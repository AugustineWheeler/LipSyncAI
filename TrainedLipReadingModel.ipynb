{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            1.2.0\n",
      "alabaster                          0.7.12\n",
      "altgraph                           0.17.2\n",
      "anaconda-client                    1.7.2\n",
      "anaconda-navigator                 1.9.7\n",
      "anaconda-project                   0.8.3\n",
      "apache-beam                        2.40.0\n",
      "appdirs                            1.4.4\n",
      "arrow                              1.2.2\n",
      "asgiref                            3.5.2\n",
      "asn1crypto                         0.24.0\n",
      "astor                              0.8.1\n",
      "astroid                            2.2.5\n",
      "astropy                            3.2.1\n",
      "astunparse                         1.6.3\n",
      "atomicwrites                       1.3.0\n",
      "attr                               0.3.1\n",
      "attrs                              19.1.0\n",
      "Automat                            20.2.0\n",
      "avro-python3                       1.10.2\n",
      "aws-lambda-builders                1.18.0\n",
      "aws-sam-cli                        1.55.0\n",
      "aws-sam-translator                 1.50.0\n",
      "Babel                              2.7.0\n",
      "backcall                           0.1.0\n",
      "backports.functools-lru-cache      1.5\n",
      "backports.os                       0.1.1\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "backports.zoneinfo                 0.2.1\n",
      "bcrypt                             3.1.6\n",
      "beautifulsoup4                     4.7.1\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           0.9.3\n",
      "bkcharts                           0.2\n",
      "blaze                              0.11.3\n",
      "bleach                             3.1.0\n",
      "bokeh                              1.2.0\n",
      "boto                               2.49.0\n",
      "boto3                              1.24.60\n",
      "botocore                           1.27.60\n",
      "Bottleneck                         1.2.1\n",
      "boxing                             0.1.4\n",
      "cachetools                         4.2.4\n",
      "certifi                            2022.6.15\n",
      "cffi                               1.12.3\n",
      "chardet                            3.0.4\n",
      "charset-normalizer                 2.1.1\n",
      "chevron                            0.14.0\n",
      "click                              7.1.2\n",
      "cloudpickle                        2.1.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.1\n",
      "commonmark                         0.9.1\n",
      "comtypes                           1.1.7\n",
      "conda                              4.14.0\n",
      "conda-build                        3.21.9\n",
      "conda-package-handling             1.3.11\n",
      "conda-verify                       3.4.2\n",
      "config                             0.5.1\n",
      "constantly                         15.1.0\n",
      "contextlib2                        0.5.5\n",
      "cookiecutter                       2.1.1\n",
      "crcmod                             1.7\n",
      "cryptography                       2.7\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.12\n",
      "cytoolz                            0.10.0\n",
      "dask                               2.1.0\n",
      "datashape                          0.5.4\n",
      "dateparser                         1.1.1\n",
      "decorator                          4.4.0\n",
      "defusedxml                         0.6.0\n",
      "dill                               0.3.1.1\n",
      "distributed                        2.1.0\n",
      "Django                             3.2.15\n",
      "django-model-utils                 4.2.0\n",
      "django-ranged-fileresponse         0.1.2\n",
      "dm-tree                            0.1.7\n",
      "docker                             4.2.2\n",
      "docopt                             0.6.2\n",
      "docutils                           0.14\n",
      "drf-dynamic-fields                 0.3.0\n",
      "drf-flex-fields                    0.9.5\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.0.1\n",
      "etils                              0.7.1\n",
      "expiringdict                       1.1.4\n",
      "ez-setup                           0.9\n",
      "fastavro                           1.6.0\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.0.12\n",
      "Flask                              1.1.4\n",
      "Flask-Cors                         3.0.10\n",
      "flatbuffers                        23.3.3\n",
      "fonttools                          4.36.0\n",
      "future                             0.17.1\n",
      "gast                               0.3.3\n",
      "gdown                              4.7.1\n",
      "gevent                             1.4.0\n",
      "gin-config                         0.5.0\n",
      "glob2                              0.7\n",
      "google-api-core                    2.8.2\n",
      "google-api-python-client           2.57.0\n",
      "google-auth                        1.35.0\n",
      "google-auth-httplib2               0.1.0\n",
      "google-auth-oauthlib               0.4.6\n",
      "google-pasta                       0.2.0\n",
      "googleapis-common-protos           1.56.4\n",
      "greenlet                           0.4.15\n",
      "grpcio                             1.47.0\n",
      "h5py                               2.10.0\n",
      "hdfs                               2.7.0\n",
      "heapdict                           1.0.0\n",
      "html5lib                           1.0.1\n",
      "htmlmin                            0.1.12\n",
      "httplib2                           0.20.4\n",
      "huggingface-hub                    0.2.1\n",
      "hyperlink                          21.0.0\n",
      "idna                               2.8\n",
      "imageio                            2.5.0\n",
      "imagesize                          1.1.0\n",
      "importlib-metadata                 4.12.0\n",
      "importlib-resources                5.9.0\n",
      "imutils                            0.5.3\n",
      "incremental                        21.3.0\n",
      "ipykernel                          5.1.1\n",
      "ipython                            7.6.1\n",
      "ipython_genutils                   0.2.0\n",
      "ipywidgets                         7.5.0\n",
      "isort                              4.3.21\n",
      "itsdangerous                       1.1.0\n",
      "itypes                             1.2.0\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.13.3\n",
      "Jinja2                             2.10.1\n",
      "jinja2-time                        0.2.0\n",
      "jmespath                           0.10.0\n",
      "joblib                             0.13.2\n",
      "json5                              0.8.4\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     5.3.1\n",
      "jupyter-console                    6.0.0\n",
      "jupyter-core                       4.5.0\n",
      "jupyterlab                         1.0.2\n",
      "jupyterlab-launcher                0.13.1\n",
      "jupyterlab-server                  1.0.0\n",
      "kaggle                             1.5.12\n",
      "keras                              2.11.0\n",
      "Keras-Applications                 1.0.8\n",
      "Keras-Preprocessing                1.1.2\n",
      "keyring                            18.0.0\n",
      "kiwisolver                         1.1.0\n",
      "lazy-object-proxy                  1.4.1\n",
      "libarchive-c                       2.8\n",
      "libclang                           14.0.6\n",
      "llvmlite                           0.29.0\n",
      "locket                             0.2.0\n",
      "lockfile                           0.12.2\n",
      "lvis                               0.5.3\n",
      "lxml                               4.4.1\n",
      "Markdown                           3.4.1\n",
      "MarkupSafe                         2.0.1\n",
      "matplotlib                         3.2.1\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.16\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mock                               3.0.5\n",
      "more-itertools                     7.0.0\n",
      "mpmath                             1.1.0\n",
      "msgpack                            0.6.1\n",
      "multipledispatch                   0.6.0\n",
      "navigator-updater                  0.2.1\n",
      "nbconvert                          5.5.0\n",
      "nbformat                           4.4.0\n",
      "networkx                           2.3\n",
      "nltk                               3.4.4\n",
      "nose                               1.3.7\n",
      "notebook                           6.0.0\n",
      "numba                              0.44.1\n",
      "numexpr                            2.8.3\n",
      "numpy                              1.21.6\n",
      "numpydoc                           0.9.1\n",
      "oauth2client                       4.1.3\n",
      "oauthlib                           3.2.0\n",
      "object-detection                   0.1\n",
      "odo                                0.5.1\n",
      "olefile                            0.46\n",
      "opencv-contrib-python              4.6.0.66\n",
      "opencv-python                      4.2.0.34\n",
      "opencv-python-headless             4.6.0.66\n",
      "openpyxl                           2.6.2\n",
      "opt-einsum                         3.3.0\n",
      "orjson                             3.7.12\n",
      "packaging                          21.3\n",
      "pandas                             0.24.2\n",
      "pandocfilters                      1.4.2\n",
      "parso                              0.5.0\n",
      "partd                              1.0.0\n",
      "path.py                            12.0.1\n",
      "pathlib2                           2.3.4\n",
      "patsy                              0.5.1\n",
      "pefile                             2022.5.30\n",
      "pep8                               1.7.1\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             9.2.0\n",
      "pip                                23.1.2\n",
      "pkginfo                            1.8.3\n",
      "pluggy                             0.12.0\n",
      "ply                                3.11\n",
      "portalocker                        2.5.1\n",
      "prometheus-client                  0.7.1\n",
      "promise                            2.3\n",
      "prompt-toolkit                     2.0.9\n",
      "proto-plus                         1.22.0\n",
      "protobuf                           3.19.4\n",
      "psutil                             5.6.3\n",
      "py                                 1.8.0\n",
      "py-cpuinfo                         8.0.0\n",
      "pyarrow                            7.0.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycocotools                        2.0.4\n",
      "pycodestyle                        2.5.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.19\n",
      "pycrypto                           2.6.1\n",
      "pycurl                             7.43.0.3\n",
      "pydot                              1.4.2\n",
      "pyflakes                           2.1.1\n",
      "Pygments                           2.13.0\n",
      "PyHamcrest                         2.0.2\n",
      "pyinstaller                        5.3\n",
      "pyinstaller-hooks-contrib          2022.9\n",
      "pylint                             2.3.1\n",
      "pymongo                            3.12.3\n",
      "pyodbc                             4.0.26\n",
      "pyOpenSSL                          19.0.0\n",
      "pyparsing                          2.4.7\n",
      "pypiwin32                          223\n",
      "PyQt5                              5.15.7\n",
      "PyQt5-Qt5                          5.15.2\n",
      "PyQt5-sip                          12.11.0\n",
      "PyQt6                              6.3.1\n",
      "PyQt6-Qt6                          6.3.1\n",
      "PyQt6-sip                          13.4.0\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.14.11\n",
      "PySocks                            1.7.0\n",
      "pytest                             5.0.1\n",
      "pytest-arraydiff                   0.3\n",
      "pytest-astropy                     0.5.0\n",
      "pytest-doctestplus                 0.3.0\n",
      "pytest-openfiles                   0.3.2\n",
      "pytest-remotedata                  0.3.1\n",
      "python-dateutil                    2.8.0\n",
      "python-slugify                     6.1.2\n",
      "pytz                               2019.3\n",
      "PyWavelets                         1.0.3\n",
      "pywin32                            304\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.5\n",
      "PyYAML                             5.4.1\n",
      "pyzmq                              18.0.0\n",
      "QtAwesome                          0.5.7\n",
      "qtconsole                          4.5.1\n",
      "QtPy                               1.8.0\n",
      "readme-renderer                    37.0\n",
      "regex                              2021.9.30\n",
      "requests                           2.25.1\n",
      "requests-oauthlib                  1.3.1\n",
      "requests-toolbelt                  0.9.1\n",
      "rfc3986                            2.0.0\n",
      "rich                               12.5.1\n",
      "rope                               0.14.0\n",
      "rsa                                4.9\n",
      "ruamel_yaml                        0.15.46\n",
      "rules                              2.2\n",
      "s3transfer                         0.6.0\n",
      "sacrebleu                          2.2.0\n",
      "sacremoses                         0.0.43\n",
      "scikit-image                       0.15.0\n",
      "scikit-learn                       1.0.2\n",
      "scipy                              1.4.1\n",
      "seaborn                            0.9.0\n",
      "semver                             2.13.0\n",
      "Send2Trash                         1.5.0\n",
      "sentencepiece                      0.1.97\n",
      "seqeval                            1.2.2\n",
      "serverlessrepo                     0.1.10\n",
      "service-identity                   18.1.0\n",
      "setuptools                         65.1.0\n",
      "simplegeneric                      0.8.1\n",
      "simplejson                         3.17.6\n",
      "singledispatch                     3.4.0.3\n",
      "six                                1.16.0\n",
      "snowballstemmer                    1.9.0\n",
      "sortedcollections                  1.1.2\n",
      "sortedcontainers                   2.1.0\n",
      "soupsieve                          1.8\n",
      "Sphinx                             2.1.2\n",
      "sphinxcontrib-applehelp            1.0.1\n",
      "sphinxcontrib-devhelp              1.0.1\n",
      "sphinxcontrib-htmlhelp             1.0.2\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.2\n",
      "sphinxcontrib-serializinghtml      1.1.3\n",
      "sphinxcontrib-websupport           1.1.2\n",
      "spyder                             3.3.6\n",
      "spyder-kernels                     0.5.1\n",
      "SQLAlchemy                         1.3.5\n",
      "sqlparse                           0.4.2\n",
      "statsmodels                        0.10.0\n",
      "sympy                              1.4\n",
      "tables                             3.5.2\n",
      "tabulate                           0.8.10\n",
      "tb-nightly                         2.10.0a20220811\n",
      "tblib                              1.4.0\n",
      "tensorboard                        2.11.2\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.8.1\n",
      "tensorflow                         2.11.0\n",
      "tensorflow-addons                  0.17.1\n",
      "tensorflow-datasets                4.6.0\n",
      "tensorflow-estimator               2.11.0\n",
      "tensorflow-hub                     0.12.0\n",
      "tensorflow-intel                   2.11.0\n",
      "tensorflow-io                      0.26.0\n",
      "tensorflow-io-gcs-filesystem       0.26.0\n",
      "tensorflow-metadata                1.9.0\n",
      "tensorflow-model-optimization      0.7.3\n",
      "tensorflow-object-detection-api    0.1.1\n",
      "tensorflow-probability             0.17.0\n",
      "tensorflow-text                    2.9.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.8.2\n",
      "testpath                           0.4.2\n",
      "text-unidecode                     1.3\n",
      "tf-estimator-nightly               2.11.0.dev2022082508\n",
      "tf-models-official                 2.9.2\n",
      "tf-slim                            1.1.0\n",
      "threadpoolctl                      2.2.0\n",
      "tokenizers                         0.11.4\n",
      "toml                               0.10.2\n",
      "tomlkit                            0.7.2\n",
      "toolz                              0.10.0\n",
      "torch                              1.10.2\n",
      "tornado                            6.0.3\n",
      "tqdm                               4.32.1\n",
      "traitlets                          4.3.2\n",
      "transformers                       4.18.0\n",
      "tweepy                             4.10.1\n",
      "twine                              4.0.1\n",
      "Twisted                            19.2.0\n",
      "typeguard                          2.13.3\n",
      "typing-extensions                  3.10.0.0\n",
      "tzdata                             2022.2\n",
      "tzlocal                            3.0\n",
      "ua-parser                          0.16.0\n",
      "ujson                              5.4.0\n",
      "unicodecsv                         0.14.1\n",
      "uritemplate                        4.1.1\n",
      "urllib3                            1.26.12\n",
      "user-agents                        2.2.0\n",
      "watchdog                           2.1.2\n",
      "wcwidth                            0.1.7\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   1.4.0\n",
      "Werkzeug                           1.0.1\n",
      "wget                               3.2\n",
      "wheel                              0.37.1\n",
      "widgetsnbextension                 3.5.0\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wrapt                              1.11.2\n",
      "xlrd                               1.2.0\n",
      "XlsxWriter                         1.1.8\n",
      "xlwings                            0.15.8\n",
      "xlwt                               1.3.0\n",
      "xmljson                            0.2.0\n",
      "zict                               1.0.0\n",
      "zipp                               3.8.1\n",
      "zope.interface                     4.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ast (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (2.30.0)\n",
      "Requirement already satisfied: six in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: matplotlib in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: imageio in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (2.33.1)\n",
      "Requirement already satisfied: gdown in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (4.7.1)\n",
      "Requirement already satisfied: tensorflow in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from opencv-python) (1.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: filelock in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (2.30.0)\n",
      "Requirement already satisfied: six in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (6.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " \"'\",\n",
       " '?',\n",
       " '!',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ' ']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " \"'\",\n",
       " '?',\n",
       " '!',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ' ']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([14,  9,  3, 11])>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'n', b'i', b'c', b'k'], dtype=object)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str): \n",
    "    path = bytes.decode(path.numpy())\n",
    "    #file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data_female','s34',f'{file_name}.mpg')\n",
    "    # video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data_female','align',f'{file_name}.align')\n",
    "    frames = load_video(video_path) \n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '.\\\\data\\\\s1\\\\bbal6n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbal6n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_dimensions(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the video file\")\n",
    "        return None\n",
    "\n",
    "    # Get the dimensions of the video\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    return width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 288)\n"
     ]
    }
   ],
   "source": [
    "video_path = '/Users/arnav/Desktop/lipsync/data/s1/bbaf2n.mpg'\n",
    "dimensions = get_video_dimensions(video_path)\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frames[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21,), dtype=int64, numpy=\n",
       "array([ 2,  9, 14, 39,  2, 12, 21,  5, 39,  1, 20, 39, 12, 39, 19,  9, 24,\n",
       "       39, 14, 15, 23])>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'i', 'n', ' ', 'b', 'l', 'u', 'e', ' ', 'a', 't', ' ', 'l', ' ', 's', 'i', 'x', ' ', 'n', 'o', 'w']\n"
     ]
    }
   ],
   "source": [
    "print([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin blue at l six now\n"
     ]
    }
   ],
   "source": [
    "print(''.join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.21.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (1.23.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (2.33.1)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-macosx_11_0_arm64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages (from scikit-image) (0.3)\n",
      "Downloading scikit_image-0.21.0-cp38-cp38-macosx_12_0_arm64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m84.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tifffile, PyWavelets, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 scikit-image-0.21.0 tifffile-2023.7.10\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "from scipy import ndimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "class Video(object):\n",
    "    def __init__(self, vtype='mouth', face_predictor_path=None):\n",
    "        if vtype == 'face' and face_predictor_path is None:\n",
    "            raise AttributeError('Face video needs to be accompanied by a face predictor')\n",
    "        self.face_predictor_path = face_predictor_path\n",
    "        self.vtype = vtype\n",
    "\n",
    "    def process_frames_face(self, frames):\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(self.face_predictor_path)\n",
    "        mouth_frames = self.get_frames_mouth(detector, predictor, frames)\n",
    "        self.face = np.array(frames)\n",
    "        self.mouth = np.array(mouth_frames)\n",
    "        self.set_data(mouth_frames)\n",
    "        \n",
    "    def set_data(self, frames):\n",
    "        data_frames = []\n",
    "        for frame in frames:\n",
    "            frame = frame.swapaxes(0, 1)  # swap width and height to form format W x H x C\n",
    "            if len(frame.shape) < 3:\n",
    "                frame = np.array([frame]).swapaxes(0, 2).swapaxes(0, 1)  # Add grayscale channel\n",
    "            data_frames.append(frame)\n",
    "        frames_n = len(data_frames)\n",
    "        data_frames = np.array(data_frames)  # T x W x H x C\n",
    "        # If K is defined and image_data_format is channels_first, roll the axis\n",
    "        if hasattr(self, 'K') and self.K.image_data_format() == 'channels_first':\n",
    "            data_frames = np.rollaxis(data_frames, 3)  # C x T x W x H\n",
    "        self.data = data_frames\n",
    "        self.length = frames_n\n",
    "\n",
    "    def get_frames_mouth(self, detector, predictor, frames):\n",
    "        MOUTH_WIDTH = 100\n",
    "        MOUTH_HEIGHT = 50\n",
    "        HORIZONTAL_PAD = 0.19\n",
    "        normalize_ratio = None\n",
    "        mouth_frames = []\n",
    "        for frame in frames:\n",
    "            dets = detector(frame, 1)\n",
    "            shape = None\n",
    "            for k, d in enumerate(dets):\n",
    "                shape = predictor(frame, d)\n",
    "                i = -1\n",
    "            if shape is None:  # Detector doesn't detect face, just return as is\n",
    "                return frames\n",
    "            mouth_points = []\n",
    "            for part in shape.parts():\n",
    "                i += 1\n",
    "                if i < 48:  # Only take mouth region\n",
    "                    continue\n",
    "                mouth_points.append((part.x, part.y))\n",
    "            np_mouth_points = np.array(mouth_points)\n",
    "\n",
    "            mouth_centroid = np.mean(np_mouth_points[:, -2:], axis=0)\n",
    "\n",
    "            if normalize_ratio is None:\n",
    "                mouth_left = np.min(np_mouth_points[:, :-1]) * (1.0 - HORIZONTAL_PAD)\n",
    "                mouth_right = np.max(np_mouth_points[:, :-1]) * (1.0 + HORIZONTAL_PAD)\n",
    "\n",
    "                normalize_ratio = MOUTH_WIDTH / float(mouth_right - mouth_left)\n",
    "\n",
    "            new_img_shape = (int(frame.shape[0] * normalize_ratio), int(frame.shape[1] * normalize_ratio))\n",
    "            resized_img = resize(frame, new_img_shape)\n",
    "\n",
    "            mouth_centroid_norm = mouth_centroid * normalize_ratio\n",
    "\n",
    "            mouth_l = int(mouth_centroid_norm[0] - MOUTH_WIDTH / 2)\n",
    "            mouth_r = int(mouth_centroid_norm[0] + MOUTH_WIDTH / 2)\n",
    "            mouth_t = int(mouth_centroid_norm[1] - MOUTH_HEIGHT / 2)\n",
    "            mouth_b = int(mouth_centroid_norm[1] + MOUTH_HEIGHT / 2)\n",
    "\n",
    "            mouth_crop_image = resized_img[mouth_t:mouth_b, mouth_l:mouth_r]\n",
    "\n",
    "            mouth_frames.append(mouth_crop_image)\n",
    "        return mouth_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shape_predictor_path = \"/Users/arnav/Desktop/lipsync/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "\n",
    "video = Video(vtype='face', face_predictor_path=shape_predictor_path)\n",
    "\n",
    "video_path = \"/Users/arnav/Desktop/lipsync/test_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "\n",
    "\n",
    "video.process_frames_face(frames)\n",
    "\n",
    "\n",
    "mouth_snippet = video.mouth[0]\n",
    "\n",
    "\n",
    "plt.imshow(mouth_snippet)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at l six now'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split \n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int64, numpy=\n",
       "array([ 2,  9, 14, 39,  2, 12, 21,  5, 39,  1, 20, 39,  2, 39, 14,  9, 14,\n",
       "        5, 39, 14, 15, 23])>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 75, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data/s1/srin6p.mpg'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imageio\u001b[38;5;241m.\u001b[39mmimsave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimation.gif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "imageio.mimsave('animation.gif', val[0][0], fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue sp at q five soon'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"data/s1/.mpg\"\n",
      "[ERROR:12@27152.458] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.0) /Users/xperience/GHA-OpenCV-Python/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): data/s1/.mpg in function 'icvExtractPattern'\n",
      "\n",
      "\n",
      "2024-02-02 01:55:45.322122: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 266, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 144, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/797274792.py\", line 9, in load_data\n",
      "    alignments = load_alignments(alignment_path)\n",
      "\n",
      "  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/885867866.py\", line 2, in load_alignments\n",
      "    with open(path, 'r') as f:\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 284, in _modified_open\n",
      "    return io_open(file, *args, **kwargs)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n",
      "\n",
      "\n",
      "OpenCV: Couldn't read video stream from file \"data/s1/.mpg\"\n",
      "[ERROR:13@27152.522] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.0) /Users/xperience/GHA-OpenCV-Python/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): data/s1/.mpg in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\nTraceback (most recent call last):\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 266, in __call__\n    return func(device, token, args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 144, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in _call\n    ret = self._func(*args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/797274792.py\", line 9, in load_data\n    alignments = load_alignments(alignment_path)\n\n  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/885867866.py\", line 2, in load_alignments\n    with open(path, 'r') as f:\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 284, in _modified_open\n    return io_open(file, *args, **kwargs)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_numpy_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4703\u001b[0m, in \u001b[0;36m_NumpyIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 4703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4700\u001b[0m, in \u001b[0;36m_NumpyIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4697\u001b[0m     numpy\u001b[38;5;241m.\u001b[39msetflags(write\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4698\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m numpy\n\u001b[0;32m-> 4700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(to_numpy, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:814\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    813\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:777\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 777\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3028\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3028\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3030\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\nTraceback (most recent call last):\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 266, in __call__\n    return func(device, token, args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 144, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in _call\n    ret = self._func(*args)\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/797274792.py\", line 9, in load_data\n    alignments = load_alignments(alignment_path)\n\n  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/885867866.py\", line 2, in load_alignments\n    with open(path, 'r') as f:\n\n  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 284, in _modified_open\n    return io_open(file, *args, **kwargs)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 01:55:45.373493: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 266, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 144, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/797274792.py\", line 9, in load_data\n",
      "    alignments = load_alignments(alignment_path)\n",
      "\n",
      "  File \"/var/folders/tl/zv5_pc09609g03x343v11n3r0000gn/T/ipykernel_27786/885867866.py\", line 2, in load_alignments\n",
      "    with open(path, 'r') as f:\n",
      "\n",
      "  File \"/Users/arnav/miniconda3/envs/mlt/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 284, in _modified_open\n",
      "    return io_open(file, *args, **kwargs)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/alignments/s1/.align'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 75, 46, 140, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 75, 46, 140, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3  (None, 75, 23, 70, 128)   0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 75, 6375)          0         \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 75, 256)           6660096   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8471924 (32.32 MB)\n",
      "Trainable params: 8471924 (32.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6375"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*17*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:959\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    960\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp4444gggg'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp4444gggg'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 46, 140, 1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 41)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Options and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/steps - loss: 84.128\n",
      "Original: set white by v five again\n",
      "Prediction: le e e e e o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay white with s five soon\n",
      "Prediction: le e e e o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 18259s 40s/step - loss: 84.1284 - val_loss: 68.5418 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 70.2446\n",
      "Original: lay green by s six now\n",
      "Prediction: la e e e e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red by t zero now\n",
      "Prediction: la e e e e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 28643s 64s/step - loss: 70.2446 - val_loss: 64.3548 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 66.5386\n",
      "Original: set white in b two now\n",
      "Prediction: la e e t e oa\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white with p four please\n",
      "Prediction: la e e t e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 28882s 64s/step - loss: 66.5386 - val_loss: 61.9074 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 63.911\n",
      "Original: set red in t nine soon\n",
      "Prediction: la e t e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red at e three soon\n",
      "Prediction: la e t e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17404s 39s/step - loss: 63.9116 - val_loss: 59.9088 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 61.973\n",
      "Original: lay red at e two now\n",
      "Prediction: la re i e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay white at l two now\n",
      "Prediction: la re i e on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17532s 39s/step - loss: 61.9736 - val_loss: 57.7827 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 59.875\n",
      "Original: place white with r one again\n",
      "Prediction: la re t e on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue at a six please\n",
      "Prediction: la re t e eae\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17615s 39s/step - loss: 59.8753 - val_loss: 56.2763 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 58.275\n",
      "Original: place green by r zero now\n",
      "Prediction: la re t e on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set green in o six now\n",
      "Prediction: la re n o o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17273s 38s/step - loss: 58.2753 - val_loss: 54.6366 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 56.869\n",
      "Original: lay green in l four now\n",
      "Prediction: la re n o o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red with n three again\n",
      "Prediction: la re t e on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17077s 38s/step - loss: 56.8698 - val_loss: 53.1740 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 3s 3s/steps - loss: 53.388\n",
      "Original: bin red at f nine soon\n",
      "Prediction: la re n o o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay white in l zero please\n",
      "Prediction: la re t e e ae\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17060s 38s/step - loss: 53.3885 - val_loss: 48.3245 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 51.174\n",
      "Original: place red in v six please\n",
      "Prediction: pla re t e lae\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place blue by i nine soon\n",
      "Prediction: pla re i o o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17043s 38s/step - loss: 51.1741 - val_loss: 46.6203 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 49.646\n",
      "Original: bin red by g three soon\n",
      "Prediction: la re t e an\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay white at z two please\n",
      "Prediction: la re t e plae\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17168s 38s/step - loss: 49.6465 - val_loss: 45.3055 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 48.113\n",
      "Original: place green in x six now\n",
      "Prediction: la re it on o\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place blue in b nine again\n",
      "Prediction: la re i ie aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17153s 38s/step - loss: 48.1134 - val_loss: 43.4701 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 46.513\n",
      "Original: bin green in g seven soon\n",
      "Prediction: pla re i ie on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin blue by s four now\n",
      "Prediction: pla bre b e ow\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17117s 38s/step - loss: 46.5132 - val_loss: 41.6871 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 3s 3s/steps - loss: 44.251\n",
      "Original: place green with r five soon\n",
      "Prediction: pla bre bt ie on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin white sp with n six now\n",
      "Prediction: la re it ie on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17113s 38s/step - loss: 44.2514 - val_loss: 38.5213 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 41.929\n",
      "Original: bin green by u two now\n",
      "Prediction: bla re y o ow\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red in k three soon\n",
      "Prediction: sla re it ie on\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 17049s 38s/step - loss: 41.9293 - val_loss: 37.0689 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 39.465\n",
      "Original: place blue at p zero please\n",
      "Prediction: plac blue by oe plae\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place white with r zero please\n",
      "Prediction: lac gre it oe plase\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 16971s 38s/step - loss: 39.4658 - val_loss: 34.3599 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 37.168\n",
      "Original: bin blue in l four please\n",
      "Prediction: plac blue by or plase\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white with v six now\n",
      "Prediction: set re it ie now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 16479s 37s/step - loss: 37.1682 - val_loss: 31.8113 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 34.634\n",
      "Original: place red at j zero now\n",
      "Prediction: play re i o now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin blue with m seven again\n",
      "Prediction: pla blue it e ain\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 16599s 37s/step - loss: 34.6344 - val_loss: 27.5767 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 32.148\n",
      "Original: set red in t eight now\n",
      "Prediction: sit whie it i now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set red by o two now\n",
      "Prediction: set re by o now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 20590s 46s/step - loss: 32.1482 - val_loss: 25.8863 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/steps - loss: 29.365\n",
      "Original: lay blue by k four now\n",
      "Prediction: play blue by fo now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red by m six now\n",
      "Prediction: bin re by fo now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 16785s 37s/step - loss: 29.3655 - val_loss: 24.8048 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 9s 9s/steps - loss: 27.0580\n",
      "Original: lay blue with k nine soon\n",
      "Prediction: la blue it nine son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place green by y six please\n",
      "Prediction: place gre by or please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 34317s 76s/step - loss: 27.0580 - val_loss: 22.0676 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 8s 8s/steps - loss: 24.914\n",
      "Original: bin white sp by n four please\n",
      "Prediction: bin white by or plese\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white in u five soon\n",
      "Prediction: set white in ie son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 25783s 57s/step - loss: 24.9144 - val_loss: 18.5779 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "108/450 [======>.......................] - ETA: 3:39:41 - loss: 22.9647"
     ]
    }
   ],
   "source": [
    "# model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "output = 'checkpoints.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2d65e57f0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models_/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = load_data(tf.convert_to_tensor('/Users/arnav/Desktop/lipsync/data_female/s34/bbac1p.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at c one please'>]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 03:54:19.474816: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 0 out of bounds.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoding_the_words\u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctc_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_alignments\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/arnav/Desktop/lipsync/data_female/s34/bbab9n.align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mlt/lib/python3.8/site-packages/keras/src/backend.py:7193\u001b[0m, in \u001b[0;36mctc_decode\u001b[0;34m(y_pred, input_length, greedy, beam_width, top_paths)\u001b[0m\n\u001b[1;32m   7164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decodes the output of a softmax.\u001b[39;00m\n\u001b[1;32m   7165\u001b[0m \n\u001b[1;32m   7166\u001b[0m \u001b[38;5;124;03mCan use either greedy search (also known as best path)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7190\u001b[0m \u001b[38;5;124;03m            the log probability of each decoded sequence.\u001b[39;00m\n\u001b[1;32m   7191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7192\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m shape(y_pred)\n\u001b[0;32m-> 7193\u001b[0m num_samples, num_steps \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   7194\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m   7195\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtranspose(y_pred, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m epsilon()\n\u001b[1;32m   7196\u001b[0m )\n\u001b[1;32m   7197\u001b[0m input_length \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(input_length, tf\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "decoding_the_words= tf.keras.backend.ctc_decode(), input_length=[75], greedy=True)[0][0].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'plac ble sis s s sene sain be ith o'>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoding_the_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
